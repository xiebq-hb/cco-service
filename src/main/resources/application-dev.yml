# 基本配置
server:
  port: 8081
  tomcat:
    uri-encoding: UTF-8

# spring 配置
spring:
  # ============== datasource ===================
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/jt?useUnicode=true&characterEncoding=utf-8&serverTimezone=GMT%2B8&useSSL=false
    username: root
    password:
    platform: mysql
    druid:
      # 初始连接数
      initial-size: 5
      # 最小连接池数量
      min-idle: 10
      # 最大连接池数量
      max-active: 20
      # 配置获取连接等待超时的时间
      max-wait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      time-between-eviction-runs-millis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 300000
      # 配置一个连接在池中最大生存的时间，单位是毫秒
      max-evictable-idle-time-millis: 900000
      # 配置检测连接是否有效
      validation-query: SELECT 1 FROM DUAL
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      web-stat-filter:
        enabled: true
      stat-view-servlet:
        enabled: true
        # 设置白名单，不填则允许所有访问
        allow:
        url-pattern: /druid/*
        # 控制台管理用户名和密码
        login-username: cco_admin
        login-password: cco#1admin
      filter:
        stat:
          enabled: true
          # 慢SQL记录
          log-slow-sql: true
          slow-sql-millis: 1000
          merge-sql: true
        wall:
          enabled: true
          config:
            multi-statement-allow: true
  # ============== redis ===================
  redis:
    #host: localhost
    #port: 6379
    password:
    # 逗号隔开
    clusters: 127.0.0.1:6385,127.0.0.1:6380,127.0.0.1:6381,127.0.0.1:6382,127.0.0.1:6383,127.0.0.1:6384
    database: 0
    timeout: 15000ms
    jedis:
      pool:
        max-idle: 20
        min-idle: 2
        max-wait: 5000ms
        max-active: 50
  # ============== kafka ===================
  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: localhost:9092
    #=============== provider  =======================
    producer:
      #retries: 0
      #  每次批量发送消息的数量
      #batch-size: 16384
      #buffer-memory: 33554432
      #  指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer

    #=============== consumer  =======================
    consumer:
      # 指定默认消费者group id
      group-id: group_id
      auto-offset-reset: earliest
      enable-auto-commit: true
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

# ============== mybatis-plus ===================
mybatis-plus:
  mapper-locations: classpath*:/mapper/*Mapper.xml
  type-aliases-package: com.cco.ccoservice.business.entity
  global-config:
    # 主键类型  0:"数据库ID自增", 1:"用户输入ID",2:"全局唯一ID (数字类型唯一ID)", 3:"全局唯一ID UUID";
    id-type: 3
    # 字段策略 0:"忽略判断",1:"非 NULL 判断"),2:"非空判断"
    field-strategy: 0
    # 驼峰下划线转换
    db-column-underline: true
    # 刷新mapper 调试神器
    refresh-mapper: true
    # 数据库大写下划线转换
    #capital-mode: true

# ============== log ===================
logging:
  config: classpath:logback-setting-dev.xml
  level:
    com.cco.ccoservice: info



